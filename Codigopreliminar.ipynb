{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convnet_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_z2lolv5HJNe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "9hI8tV5uVHZX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Subir código cifar10.py. Basta con ejecutar una vez (inmune a reinicios de kernel de python, no de la máquina)"
      ]
    },
    {
      "metadata": {
        "id": "x7EKoANMPBps",
        "colab_type": "code",
        "outputId": "5c09e569-24db-4b5f-cd16-9043c2ec3bc2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1de6a63f-b9a0-44ad-aec0-1c1785714ec6\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1de6a63f-b9a0-44ad-aec0-1c1785714ec6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cifar10.py to cifar10.py\n",
            "User uploaded file \"cifar10.py\" with length 6585 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pgIK9vPiSHU1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Aquí comienza el cuerpo del código\n",
        "## Reinicie luego de entrenar cada modelo. Recuerde actualizar el directorio de tensorboard."
      ]
    },
    {
      "metadata": {
        "id": "vFrRwKUHOhs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "import tensorflow as tf\n",
        "\n",
        "from cifar10 import CIFAR10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVjsrPpMOhtI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.set_random_seed(1)\n",
        "sess = tf.Session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYzZFJpM08iZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Constructor del dataset. Modifique aquí el *flag* de *data augmentation*"
      ]
    },
    {
      "metadata": {
        "id": "1Hk74ROkOhtO",
        "colab_type": "code",
        "outputId": "cc8ffa9d-d932-4df8-c3c6-5e1564490a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "batch_size = 64\n",
        "\n",
        "cifar10 = CIFAR10(batch_size=batch_size, validation_proportion=0.1, augment_data=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b16c8f9071e6>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    dataset = files.interleave(tf.data.TFRecordDataset)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "g-b91thwOhtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model blocks\n",
        "def conv_layer(input_tensor, kernel_shape, layer_name):\n",
        "    # input_tensor b01c\n",
        "    # kernel_shape 01-in-out\n",
        "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
        "                               initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
        "    biases = tf.get_variable(\"biases\", [kernel_shape[3]],\n",
        "                             initializer=tf.constant_initializer(0.05))\n",
        "    \n",
        "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
        "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
        "    \n",
        "    # Other options are to use He et. al init. for weights and 0.01 \n",
        "    # to init. biases.\n",
        "    conv = tf.nn.conv2d(input_tensor, weights, \n",
        "                       strides = [1, 1, 1, 1], padding='SAME')\n",
        "    return tf.nn.relu(conv + biases)\n",
        "\n",
        "def fc_layer(input_tensor, weights_shape, layer_name):\n",
        "    # weights_shape in-out\n",
        "    weights = tf.get_variable(\"weights\", weights_shape,\n",
        "                              initializer = tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(\"biases\", [weights_shape[1]],\n",
        "                             initializer=tf.constant_initializer(0.0))\n",
        "    tf.summary.histogram(layer_name + \"/weights\", weights)\n",
        "    tf.summary.histogram(layer_name + \"/biases\", biases)\n",
        "    mult_out = tf.matmul(input_tensor, weights)\n",
        "    return tf.nn.relu(mult_out+biases)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCAGDv5M0hFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elija aquí el directorio donde guardará los registros de Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "AaGDU7CF0p71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Construcción del grafo"
      ]
    },
    {
      "metadata": {
        "id": "yqn2fJpRUYkr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PARENT_DIR = './summaries/'\n",
        "SUMMARIES_DIR = PARENT_DIR + 'conv11111111111'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOgKrUip2bwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del modelo + función de costos"
      ]
    },
    {
      "metadata": {
        "id": "_Y0ezm__OhtY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model\n",
        "use_convnet = True\n",
        "n_conv_layers = 3\n",
        "\n",
        "n_filters_convs = [16, 32, 64]\n",
        "\n",
        "model_input = tf.placeholder(tf.float32, name='model_input', \n",
        "                             shape=(batch_size, 32, 32, 3))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32, name='dropout_prob', shape=())\n",
        "\n",
        "target = tf.placeholder(tf.float32, name='target', shape=(batch_size, 10))\n",
        "\n",
        "if use_convnet:\n",
        "    layer_input = model_input\n",
        "    previous_n_feature_maps = 3\n",
        "    for layer_index in range(n_conv_layers):\n",
        "      layer_name = 'conv%d' % layer_index\n",
        "      with tf.variable_scope(layer_name):\n",
        "        conv_out = conv_layer(\n",
        "            layer_input, \n",
        "            [5, 5, previous_n_feature_maps, n_filters_convs[layer_index]], \n",
        "            layer_name)\n",
        "      if layer_index == 0:\n",
        "        with tf.variable_scope(layer_name, reuse=True):\n",
        "          conv1_filters = tf.get_variable(\"weights\")\n",
        "          tf.summary.image(\n",
        "              'conv1_filters',\n",
        "              tf.transpose(conv1_filters, perm=[3, 0, 1, 2]),\n",
        "              max_outputs=n_filters_convs[layer_index]\n",
        "          )\n",
        "      previous_n_feature_maps = n_filters_convs[layer_index]\n",
        "      pool_out = tf.nn.max_pool(\n",
        "          conv_out, \n",
        "          ksize=[1, 2, 2, 1],\n",
        "          strides=[1, 2, 2, 1],\n",
        "          padding='SAME',\n",
        "          name='pool%d' % layer_index)\n",
        "      layer_input = pool_out\n",
        "     \n",
        "\n",
        "    fc_input = tf.layers.flatten(pool_out, name='fc_input')\n",
        "\n",
        "    feature_map_height = int(32 / (2**n_conv_layers))\n",
        "    \n",
        "    # First fully connected layer\n",
        "    layer_name = 'fc1'\n",
        "    with tf.variable_scope(layer_name):\n",
        "        fc1_out = fc_layer(\n",
        "            fc_input, \n",
        "            [(feature_map_height**2)*previous_n_feature_maps, 50], \n",
        "            layer_name)\n",
        "\n",
        "    fc1_out_drop = tf.nn.dropout(fc1_out, keep_prob)\n",
        "\n",
        "    # Second fully connected layer\n",
        "    layer_name = 'fc2'\n",
        "    with tf.variable_scope(layer_name):\n",
        "        fc2_out = fc_layer(fc1_out_drop, [50, 10], layer_name)\n",
        "    model_output = fc2_out\n",
        "        \n",
        "else:\n",
        "    # Reshape tensor to MLP\n",
        "    first_layer_input = tf.reshape(model_input, [-1,3072], name='first_layer_input')\n",
        "\n",
        "    # First layer\n",
        "    layer_name = 'fc1'\n",
        "    with tf.variable_scope(layer_name):\n",
        "        fc1_out = fc_layer(first_layer_input, [3072, 100], layer_name)\n",
        "\n",
        "    fc1_out_drop = tf.nn.dropout(fc1_out, keep_prob)\n",
        "\n",
        "    # Second layer\n",
        "    layer_name = 'fc2'\n",
        "    with tf.variable_scope(layer_name):\n",
        "        fc2_out = fc_layer(fc1_out_drop, [100, 10], layer_name)\n",
        "    model_output = fc2_out\n",
        "\n",
        "with tf.name_scope('loss_function'):\n",
        "    cross_entropy = tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits(logits=model_output, labels=target,\n",
        "                                           name='cross_entropy'))\n",
        "    xentropy_summary = tf.summary.scalar('cross_entropy', cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAIrQw7r2E47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construcción del optimizador + funciones auxiliares"
      ]
    },
    {
      "metadata": {
        "id": "wnMUAQYlOhtc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Optimization\n",
        "with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.train.RMSPropOptimizer(0.0005)\n",
        "    grads_vars = optimizer.compute_gradients(cross_entropy)\n",
        "    optimizer.apply_gradients(grads_vars)\n",
        "    train_step = optimizer.minimize(cross_entropy)\n",
        "\n",
        "# Metrics\n",
        "correct_prediction = tf.equal(tf.argmax(model_output, 1),\n",
        "                             tf.argmax(target, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
        "learning_summaries = tf.summary.merge((xentropy_summary, accuracy_summary))\n",
        "merged = tf.summary.merge_all()\n",
        "\n",
        "# Useful training functions\n",
        "def validate():\n",
        "    cifar10.shuffleValidation()\n",
        "    batches = cifar10.getValidationSet(asBatches=True)\n",
        "    accs = []\n",
        "    xent_vals = []\n",
        "    for batch in batches:\n",
        "        data, labels = batch\n",
        "        acc, xentropy_val = sess.run((accuracy, cross_entropy),\n",
        "                       feed_dict={\n",
        "                model_input: data,\n",
        "                target: labels,\n",
        "                keep_prob: 1.0\n",
        "            })\n",
        "        accs.append(acc)\n",
        "        xent_vals.append(xentropy_val)\n",
        "    mean_xent = np.array(xent_vals).mean()    \n",
        "    mean_acc = np.array(accs).mean()\n",
        "    summary = sess.run(\n",
        "        merged,\n",
        "        feed_dict={\n",
        "            model_input: data,\n",
        "            target: labels,\n",
        "            keep_prob: 1.0\n",
        "        })\n",
        "    return summary, mean_acc, mean_xent\n",
        "def test():\n",
        "    batches = cifar10.getTestSet(asBatches=True)\n",
        "    accs = []\n",
        "    for batch in batches:\n",
        "        data, labels = batch\n",
        "        acc = sess.run(accuracy,\n",
        "                       feed_dict={\n",
        "                model_input: data,\n",
        "                target: labels,\n",
        "                keep_prob: 1.0\n",
        "            })\n",
        "        accs.append(acc)\n",
        "    mean_acc = np.array(accs).mean()\n",
        "    return mean_acc\n",
        "\n",
        "# Tensorboard writers\n",
        "train_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/train',\n",
        "                                     sess.graph)\n",
        "validation_writer = tf.summary.FileWriter(SUMMARIES_DIR+'/validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUc5-KOHSALR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Entrenar\n",
        "### Modifique el valor de *keep_prob* usado al computar *train_step* para activar/desactivar el *dropout*.\n",
        "### NO MODIFIQUE EL KEEP_PROB USADO EN OTROS SITIOS, ESOS CORRESPONDEN A INFERENCIA."
      ]
    },
    {
      "metadata": {
        "id": "h554rbJcR7Jj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualizar en Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "aL3_pq6eOhtl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----- Descarga de ngrok para crear tunel\n",
        "%%bash\n",
        "file=\"ngrok-stable-linux-amd64.zip\"\n",
        "if [ -f \"$file\" ]\n",
        "then\n",
        "\techo \"$file already downloaded.\"\n",
        "else\n",
        "    wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "    unzip ngrok-stable-linux-amd64.zip\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "TRKMxMztOhtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "cifar10.reset()\n",
        "print(\"Trainable variables\")\n",
        "for n in tf.trainable_variables():\n",
        "    print(n.name)\n",
        "if use_convnet:\n",
        "    epochs = 30\n",
        "else:\n",
        "    epochs = 50\n",
        "    \n",
        "t_i = time.time()\n",
        "n_batches = cifar10.n_batches\n",
        "val_acc_vals = []\n",
        "test_acc_vals = []\n",
        "while cifar10.getEpoch() < epochs:\n",
        "    epoch = cifar10.getEpoch()\n",
        "    batch, batch_idx = cifar10.nextBatch()\n",
        "    batch_data = batch[0]\n",
        "    batch_labels = batch[1]\n",
        "    \n",
        "    # just a training iteration\n",
        "    _ = sess.run(train_step,\n",
        "                feed_dict={\n",
        "            model_input: batch_data,\n",
        "            target: batch_labels,\n",
        "            keep_prob: 1.0 ###### Modifique el dropout aqui y solo aqui. #####\n",
        "        })\n",
        "    \n",
        "    step = batch_idx+epoch*n_batches\n",
        "    \n",
        "    # Write training summary\n",
        "    if step%50==0:\n",
        "        summary = sess.run(learning_summaries,\n",
        "                          feed_dict={\n",
        "                model_input: batch_data,\n",
        "                target: batch_labels,\n",
        "                keep_prob: 1.0 # set to 1.0 at inference time\n",
        "            })\n",
        "        train_writer.add_summary(summary, step)\n",
        "        \n",
        "    if step%100==0:\n",
        "           run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
        "           run_metadata = tf.RunMetadata()\n",
        "           summary = sess.run(learning_summaries,\n",
        "                          feed_dict={\n",
        "           model_input: batch_data,\n",
        "           target: batch_labels,\n",
        "           keep_prob: 1.0  \n",
        "                          }, options=run_options, run_metadata=run_metadata)\n",
        "           train_writer.add_run_metadata(run_metadata, 'ea%03d' % step)\n",
        "           train_writer.add_summary(summary, step)\n",
        "           print('Adding run metadata for', step)\n",
        "    # gradient (by layer) statistics over last training batch & validation summary\n",
        " \n",
        "    if batch_idx==0:\n",
        "        loss, acc, grads = sess.run((cross_entropy, accuracy, grads_vars), \n",
        "                      feed_dict={\n",
        "            model_input: batch_data,\n",
        "            target: batch_labels,\n",
        "            keep_prob: 1.0\n",
        "        })\n",
        "        \n",
        "        summary, validation_accuracy, validation_loss = validate()\n",
        "        validation_writer.add_summary(summary, step)\n",
        "        print('[Epoch %d, it %d] Training acc. %.3f, loss %.3f. \\\n",
        "Valid. acc. %.3f, loss %.3f' % (\n",
        "            epoch,\n",
        "            step,\n",
        "            acc,\n",
        "            loss,\n",
        "            validation_accuracy,\n",
        "            validation_loss\n",
        "        ))\n",
        "        val_acc_vals.append(validation_accuracy)\n",
        "        test_accuracy = test()\n",
        "        test_acc_vals.append(test_accuracy)\n",
        "        print(\"Time elapsed %.2f minutes\" % ((time.time()-t_i)/60.0))\n",
        "train_writer.flush()\n",
        "validation_writer.flush()\n",
        "\n",
        "val_acc_vals = np.array(val_acc_vals)\n",
        "test_acc_vals = np.array(test_acc_vals)\n",
        "best_epoch = np.argmax(val_acc_vals)\n",
        "test_acc_at_best = test_acc_vals[best_epoch]\n",
        "print('*'*30)\n",
        "print(\"Testing set accuracy @ epoch %d (best validation acc): %.4f\" % (best_epoch, test_acc_at_best))\n",
        "print('*'*30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "baPlJx8YT2IL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ----- Ejecutar despues de nueva corrida para actualizar Tensorboard\n",
        "print(\"Showing summaries at %s\" % (PARENT_DIR))\n",
        "\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(PARENT_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "print('Click URL to open TensorBoard:')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUYkbGcHT3Vz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ls\n",
        "ps aux | grep -e 'tensorboard'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8pQhqcWQd0NM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}